{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• √âvaluation des Mod√®les de Pr√©diction - Piti√©-Salp√™tri√®re\n",
    "\n",
    "Ce notebook permet de :\n",
    "1. **Charger et explorer** les donn√©es (synth√©tiques et r√©elles)\n",
    "2. **Entra√Æner** les mod√®les ARIMA et Random Forest\n",
    "3. **√âvaluer** les performances avec m√©triques compl√®tes\n",
    "4. **Visualiser** les r√©sultats (courbes, matrices, importance features)\n",
    "5. **Backtester** sur donn√©es COVID r√©elles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances si n√©cessaire\n",
    "# !pip install pandas numpy scikit-learn statsmodels matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Statsmodels pour ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Config plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"‚úÖ Librairies charg√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins\n",
    "DATA_DIR = Path(\"../data\")\n",
    "EXTERNAL_DIR = DATA_DIR / \"external\"\n",
    "\n",
    "# Charger donn√©es synth√©tiques\n",
    "df_admissions = pd.read_csv(DATA_DIR / \"admissions.csv\")\n",
    "df_admissions['date'] = pd.to_datetime(df_admissions['date_admission'])\n",
    "\n",
    "print(f\"üìä Dataset synth√©tique: {len(df_admissions):,} admissions\")\n",
    "print(f\"   P√©riode: {df_admissions['date'].min().date()} ‚Üí {df_admissions['date'].max().date()}\")\n",
    "df_admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agr√©gation journali√®re\n",
    "df_daily = df_admissions.groupby('date').agg({\n",
    "    'id_patient': 'count',\n",
    "    'duree_sejour': 'mean',\n",
    "    'cout_sejour': ['sum', 'mean'],\n",
    "    'age': 'mean',\n",
    "    'gravite': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df_daily.columns = ['date', 'admissions', 'duree_moyenne', 'cout_total', 'cout_moyen', 'age_moyen', 'gravite_moyenne']\n",
    "df_daily = df_daily.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"üìÖ Donn√©es journali√®res: {len(df_daily)} jours\")\n",
    "print(f\"   Moyenne admissions/jour: {df_daily['admissions'].mean():.1f}\")\n",
    "print(f\"   Min/Max: {df_daily['admissions'].min()} / {df_daily['admissions'].max()}\")\n",
    "\n",
    "df_daily.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger donn√©es r√©elles COVID (Paris)\n",
    "try:\n",
    "    df_covid = pd.read_csv(EXTERNAL_DIR / \"hospitalisations_covid.csv\", sep=\";\")\n",
    "    df_covid['jour'] = pd.to_datetime(df_covid['jour'])\n",
    "    df_covid_paris = df_covid[df_covid['dep'] == '75'].copy()\n",
    "    df_covid_paris = df_covid_paris.sort_values('jour').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"ü¶† Donn√©es COVID Paris: {len(df_covid_paris)} jours\")\n",
    "    print(f\"   P√©riode: {df_covid_paris['jour'].min().date()} ‚Üí {df_covid_paris['jour'].max().date()}\")\n",
    "    print(f\"   Moyenne hospitalisations/jour: {df_covid_paris['incid_hosp'].mean():.1f}\")\n",
    "    HAS_COVID_DATA = True\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Donn√©es COVID non disponibles: {e}\")\n",
    "    HAS_COVID_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration et Visualisation des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des admissions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# S√©rie temporelle\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df_daily['date'], df_daily['admissions'], alpha=0.7, linewidth=0.8)\n",
    "ax1.plot(df_daily['date'], df_daily['admissions'].rolling(30).mean(), 'r-', linewidth=2, label='Moyenne mobile 30j')\n",
    "ax1.set_title('Admissions Journali√®res')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Admissions')\n",
    "ax1.legend()\n",
    "\n",
    "# Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df_daily['admissions'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(df_daily['admissions'].mean(), color='r', linestyle='--', label=f'Moyenne: {df_daily[\"admissions\"].mean():.0f}')\n",
    "ax2.set_title('Distribution des Admissions')\n",
    "ax2.set_xlabel('Admissions/jour')\n",
    "ax2.set_ylabel('Fr√©quence')\n",
    "ax2.legend()\n",
    "\n",
    "# Par jour de la semaine\n",
    "ax3 = axes[1, 0]\n",
    "df_daily['jour_semaine'] = df_daily['date'].dt.dayofweek\n",
    "jours = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "weekly_avg = df_daily.groupby('jour_semaine')['admissions'].mean()\n",
    "colors = ['#3498db' if i < 5 else '#e74c3c' for i in range(7)]\n",
    "ax3.bar(jours, weekly_avg, color=colors)\n",
    "ax3.set_title('Moyenne par Jour de la Semaine')\n",
    "ax3.set_ylabel('Admissions moyennes')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Par mois\n",
    "ax4 = axes[1, 1]\n",
    "df_daily['mois'] = df_daily['date'].dt.month\n",
    "monthly_avg = df_daily.groupby('mois')['admissions'].mean()\n",
    "mois_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, 12))\n",
    "ax4.bar(mois_names, monthly_avg, color=colors)\n",
    "ax4.set_title('Moyenne par Mois (Saisonnalit√©)')\n",
    "ax4.set_ylabel('Admissions moyennes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz_exploration_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pr√©paration des Features pour le ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, target_col='admissions'):\n",
    "    \"\"\"Cr√©e les features pour le mod√®le ML.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features temporelles\n",
    "    df['jour_semaine'] = df['date'].dt.dayofweek\n",
    "    df['jour_mois'] = df['date'].dt.day\n",
    "    df['mois'] = df['date'].dt.month\n",
    "    df['semaine_annee'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['annee'] = df['date'].dt.year\n",
    "    \n",
    "    # Encodage cyclique (pour capturer la circularit√©)\n",
    "    df['sin_jour_semaine'] = np.sin(2 * np.pi * df['jour_semaine'] / 7)\n",
    "    df['cos_jour_semaine'] = np.cos(2 * np.pi * df['jour_semaine'] / 7)\n",
    "    df['sin_mois'] = np.sin(2 * np.pi * df['mois'] / 12)\n",
    "    df['cos_mois'] = np.cos(2 * np.pi * df['mois'] / 12)\n",
    "    df['sin_semaine'] = np.sin(2 * np.pi * df['semaine_annee'] / 52)\n",
    "    df['cos_semaine'] = np.cos(2 * np.pi * df['semaine_annee'] / 52)\n",
    "    \n",
    "    # Indicateurs binaires\n",
    "    df['est_weekend'] = (df['jour_semaine'] >= 5).astype(int)\n",
    "    df['est_lundi'] = (df['jour_semaine'] == 0).astype(int)\n",
    "    df['est_vendredi'] = (df['jour_semaine'] == 4).astype(int)\n",
    "    \n",
    "    # Saisons\n",
    "    df['est_hiver'] = df['mois'].isin([12, 1, 2]).astype(int)\n",
    "    df['est_printemps'] = df['mois'].isin([3, 4, 5]).astype(int)\n",
    "    df['est_ete'] = df['mois'].isin([6, 7, 8]).astype(int)\n",
    "    df['est_automne'] = df['mois'].isin([9, 10, 11]).astype(int)\n",
    "    \n",
    "    # Features de lag (historique)\n",
    "    for lag in [1, 2, 3, 7, 14, 21, 30]:\n",
    "        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)\n",
    "    \n",
    "    # Moyennes mobiles\n",
    "    for window in [7, 14, 30]:\n",
    "        df[f'{target_col}_ma_{window}'] = df[target_col].rolling(window).mean()\n",
    "        df[f'{target_col}_std_{window}'] = df[target_col].rolling(window).std()\n",
    "        df[f'{target_col}_min_{window}'] = df[target_col].rolling(window).min()\n",
    "        df[f'{target_col}_max_{window}'] = df[target_col].rolling(window).max()\n",
    "    \n",
    "    # Tendances\n",
    "    df['tendance_7j'] = df[target_col].diff(7)\n",
    "    df['tendance_14j'] = df[target_col].diff(14)\n",
    "    \n",
    "    # Ratio vs moyenne mobile\n",
    "    df['ratio_vs_ma7'] = df[target_col] / df[f'{target_col}_ma_7']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appliquer\n",
    "df_features = create_features(df_daily)\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "print(f\"üìä Features cr√©√©es: {len(df_features.columns)} colonnes\")\n",
    "print(f\"   Lignes apr√®s dropna: {len(df_features)}\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des features √† utiliser\n",
    "FEATURE_COLS = [\n",
    "    # Temporelles\n",
    "    'jour_semaine', 'jour_mois', 'mois', 'semaine_annee',\n",
    "    # Cycliques\n",
    "    'sin_jour_semaine', 'cos_jour_semaine', 'sin_mois', 'cos_mois',\n",
    "    'sin_semaine', 'cos_semaine',\n",
    "    # Binaires\n",
    "    'est_weekend', 'est_lundi', 'est_vendredi',\n",
    "    'est_hiver', 'est_printemps', 'est_ete', 'est_automne',\n",
    "    # Lags\n",
    "    'admissions_lag_1', 'admissions_lag_2', 'admissions_lag_3',\n",
    "    'admissions_lag_7', 'admissions_lag_14', 'admissions_lag_21', 'admissions_lag_30',\n",
    "    # Moyennes mobiles\n",
    "    'admissions_ma_7', 'admissions_ma_14', 'admissions_ma_30',\n",
    "    'admissions_std_7', 'admissions_std_14', 'admissions_std_30',\n",
    "    # Tendances\n",
    "    'tendance_7j', 'tendance_14j',\n",
    "]\n",
    "\n",
    "TARGET = 'admissions'\n",
    "\n",
    "X = df_features[FEATURE_COLS]\n",
    "y = df_features[TARGET]\n",
    "\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entra√Ænement du Mod√®le Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporel (pas al√©atoire pour s√©ries temporelles!)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "dates_test = df_features['date'].iloc[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(X_train)} jours\")\n",
    "print(f\"Test: {len(X_test)} jours\")\n",
    "print(f\"P√©riode test: {dates_test.iloc[0].date()} ‚Üí {dates_test.iloc[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Entra√Ænement Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# M√©triques\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mape_rf = np.mean(np.abs((y_test - y_pred_rf) / y_test)) * 100\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"üìä M√âTRIQUES RANDOM FOREST\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE  (Erreur Absolue Moyenne): {mae_rf:.2f} admissions\")\n",
    "print(f\"RMSE (Racine Erreur Quadratique): {rmse_rf:.2f}\")\n",
    "print(f\"MAPE (Erreur % Moyenne): {mape_rf:.2f}%\")\n",
    "print(f\"R¬≤   (Coefficient D√©termination): {r2_rf:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des features\n",
    "importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLS,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_20 = importance.head(20)\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(top_20)))\n",
    "ax.barh(top_20['feature'], top_20['importance'], color=colors[::-1])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Top 20 Features les Plus Importantes (Random Forest)')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Ajouter les valeurs\n",
    "for i, (idx, row) in enumerate(top_20.iterrows()):\n",
    "    ax.text(row['importance'] + 0.002, i, f\"{row['importance']:.1%}\", va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Top 10 Features:\")\n",
    "for idx, row in importance.head(10).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison R√©el vs Pr√©dit\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. S√©rie temporelle\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(dates_test, y_test.values, 'b-', label='R√©el', alpha=0.7, linewidth=1)\n",
    "ax1.plot(dates_test, y_pred_rf, 'r-', label='Pr√©dit (RF)', alpha=0.7, linewidth=1)\n",
    "ax1.fill_between(dates_test, y_pred_rf - mae_rf, y_pred_rf + mae_rf, alpha=0.2, color='red', label='¬±MAE')\n",
    "ax1.set_title('Pr√©dictions vs R√©el (S√©rie Temporelle)')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Admissions')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Scatter plot\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test, y_pred_rf, alpha=0.5, s=20)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Parfait')\n",
    "ax2.set_xlabel('R√©el')\n",
    "ax2.set_ylabel('Pr√©dit')\n",
    "ax2.set_title(f'Scatter: R√©el vs Pr√©dit (R¬≤ = {r2_rf:.3f})')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Distribution des erreurs\n",
    "ax3 = axes[1, 0]\n",
    "errors = y_test.values - y_pred_rf\n",
    "ax3.hist(errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax3.axvline(0, color='r', linestyle='--', linewidth=2)\n",
    "ax3.axvline(errors.mean(), color='g', linestyle='--', label=f'Moyenne: {errors.mean():.2f}')\n",
    "ax3.set_title('Distribution des Erreurs (R√©sidus)')\n",
    "ax3.set_xlabel('Erreur (R√©el - Pr√©dit)')\n",
    "ax3.set_ylabel('Fr√©quence')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Erreur par jour de semaine\n",
    "ax4 = axes[1, 1]\n",
    "df_results = pd.DataFrame({\n",
    "    'date': dates_test,\n",
    "    'reel': y_test.values,\n",
    "    'predit': y_pred_rf,\n",
    "    'erreur': np.abs(errors)\n",
    "})\n",
    "df_results['jour_semaine'] = df_results['date'].dt.dayofweek\n",
    "error_by_day = df_results.groupby('jour_semaine')['erreur'].mean()\n",
    "ax4.bar(jours, error_by_day, color=['#3498db' if i < 5 else '#e74c3c' for i in range(7)])\n",
    "ax4.set_title('Erreur Absolue Moyenne par Jour')\n",
    "ax4.set_ylabel('MAE')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz_predictions_rf.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Temporelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "cv_scores_mae = []\n",
    "cv_scores_r2 = []\n",
    "\n",
    "print(\"‚è≥ Cross-validation temporelle (5 folds)...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "    X_cv_train, X_cv_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_cv_train, y_cv_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    rf_cv = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "    rf_cv.fit(X_cv_train, y_cv_train)\n",
    "    y_cv_pred = rf_cv.predict(X_cv_val)\n",
    "    \n",
    "    mae = mean_absolute_error(y_cv_val, y_cv_pred)\n",
    "    r2 = r2_score(y_cv_val, y_cv_pred)\n",
    "    cv_scores_mae.append(mae)\n",
    "    cv_scores_r2.append(r2)\n",
    "    \n",
    "    print(f\"  Fold {fold+1}: MAE = {mae:.2f}, R¬≤ = {r2:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"üìä CROSS-VALIDATION R√âSUM√â\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {np.mean(cv_scores_mae):.2f} ¬± {np.std(cv_scores_mae):.2f}\")\n",
    "print(f\"R¬≤:  {np.mean(cv_scores_r2):.3f} ¬± {np.std(cv_scores_r2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mod√®le ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de stationnarit√©\n",
    "result = adfuller(df_daily['admissions'].dropna())\n",
    "print(f\"Test ADF Stationnarit√©:\")\n",
    "print(f\"  Statistique: {result[0]:.4f}\")\n",
    "print(f\"  P-value: {result[1]:.4f}\")\n",
    "print(f\"  Stationnaire: {'Oui' if result[1] < 0.05 else 'Non (diff√©renciation n√©cessaire)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF pour d√©terminer p, q\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "plot_acf(df_daily['admissions'].dropna(), ax=axes[0], lags=40)\n",
    "axes[0].set_title('Autocorr√©lation (ACF)')\n",
    "\n",
    "plot_pacf(df_daily['admissions'].dropna(), ax=axes[1], lags=40)\n",
    "axes[1].set_title('Autocorr√©lation Partielle (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/viz_acf_pacf.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Æner ARIMA\n",
    "train_series = df_daily['admissions'].iloc[:split_idx]\n",
    "test_series = df_daily['admissions'].iloc[split_idx:]\n",
    "\n",
    "print(\"‚è≥ Entra√Ænement ARIMA(2,1,2)...\")\n",
    "try:\n",
    "    arima_model = ARIMA(train_series, order=(2, 1, 2))\n",
    "    arima_fit = arima_model.fit()\n",
    "    print(\"‚úÖ ARIMA entra√Æn√©!\")\n",
    "    print(arima_fit.summary().tables[0])\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur ARIMA: {e}\")\n",
    "    arima_fit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions ARIMA\n",
    "if arima_fit:\n",
    "    y_pred_arima = arima_fit.forecast(steps=len(test_series))\n",
    "    \n",
    "    mae_arima = mean_absolute_error(test_series, y_pred_arima)\n",
    "    rmse_arima = np.sqrt(mean_squared_error(test_series, y_pred_arima))\n",
    "    r2_arima = r2_score(test_series, y_pred_arima)\n",
    "    mape_arima = np.mean(np.abs((test_series - y_pred_arima) / test_series)) * 100\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"üìä M√âTRIQUES ARIMA\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"MAE:  {mae_arima:.2f}\")\n",
    "    print(f\"RMSE: {rmse_arima:.2f}\")\n",
    "    print(f\"MAPE: {mape_arima:.2f}%\")\n",
    "    print(f\"R¬≤:   {r2_arima:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "if arima_fit:\n",
    "    comparison = pd.DataFrame({\n",
    "        'M√©trique': ['MAE', 'RMSE', 'MAPE (%)', 'R¬≤'],\n",
    "        'Random Forest': [mae_rf, rmse_rf, mape_rf, r2_rf],\n",
    "        'ARIMA': [mae_arima, rmse_arima, mape_arima, r2_arima]\n",
    "    })\n",
    "    comparison['Meilleur'] = comparison.apply(\n",
    "        lambda row: 'RF' if (row['Random Forest'] < row['ARIMA'] if row['M√©trique'] != 'R¬≤' else row['Random Forest'] > row['ARIMA']) else 'ARIMA', \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä COMPARAISON DES MOD√àLES\")\n",
    "    print(\"=\"*60)\n",
    "    print(comparison.to_string(index=False))\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparaison\n",
    "if arima_fit:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # S√©rie temporelle\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(dates_test, test_series.values, 'b-', label='R√©el', linewidth=1.5)\n",
    "    ax1.plot(dates_test, y_pred_rf, 'g-', label=f'RF (MAE={mae_rf:.1f})', alpha=0.8)\n",
    "    ax1.plot(dates_test, y_pred_arima, 'r-', label=f'ARIMA (MAE={mae_arima:.1f})', alpha=0.8)\n",
    "    ax1.set_title('Comparaison RF vs ARIMA')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Admissions')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Barres m√©triques\n",
    "    ax2 = axes[1]\n",
    "    x = np.arange(3)\n",
    "    width = 0.35\n",
    "    metrics = ['MAE', 'RMSE', 'MAPE (%)']\n",
    "    rf_vals = [mae_rf, rmse_rf, mape_rf]\n",
    "    arima_vals = [mae_arima, rmse_arima, mape_arima]\n",
    "    \n",
    "    bars1 = ax2.bar(x - width/2, rf_vals, width, label='Random Forest', color='green', alpha=0.7)\n",
    "    bars2 = ax2.bar(x + width/2, arima_vals, width, label='ARIMA', color='red', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(metrics)\n",
    "    ax2.set_title('M√©triques de Performance')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Valeurs sur les barres\n",
    "    for bar, val in zip(bars1, rf_vals):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{val:.1f}', ha='center', fontsize=9)\n",
    "    for bar, val in zip(bars2, arima_vals):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{val:.1f}', ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/viz_comparison_models.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Backtest sur Donn√©es COVID R√©elles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_COVID_DATA:\n",
    "    print(\"ü¶† BACKTEST SUR DONN√âES COVID R√âELLES (PARIS)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Cr√©er features pour donn√©es COVID\n",
    "    df_covid_feat = df_covid_paris[['jour', 'incid_hosp']].copy()\n",
    "    df_covid_feat.columns = ['date', 'admissions']\n",
    "    df_covid_feat = create_features(df_covid_feat)\n",
    "    df_covid_feat = df_covid_feat.dropna()\n",
    "    \n",
    "    # Split\n",
    "    split_covid = int(len(df_covid_feat) * 0.7)\n",
    "    X_covid_train = df_covid_feat[FEATURE_COLS].iloc[:split_covid]\n",
    "    X_covid_test = df_covid_feat[FEATURE_COLS].iloc[split_covid:]\n",
    "    y_covid_train = df_covid_feat['admissions'].iloc[:split_covid]\n",
    "    y_covid_test = df_covid_feat['admissions'].iloc[split_covid:]\n",
    "    dates_covid_test = df_covid_feat['date'].iloc[split_covid:]\n",
    "    \n",
    "    print(f\"Train: {len(X_covid_train)} jours\")\n",
    "    print(f\"Test: {len(X_covid_test)} jours\")\n",
    "    \n",
    "    # Entra√Æner sur COVID\n",
    "    rf_covid = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "    rf_covid.fit(X_covid_train, y_covid_train)\n",
    "    y_covid_pred = rf_covid.predict(X_covid_test)\n",
    "    \n",
    "    # M√©triques\n",
    "    mae_covid = mean_absolute_error(y_covid_test, y_covid_pred)\n",
    "    rmse_covid = np.sqrt(mean_squared_error(y_covid_test, y_covid_pred))\n",
    "    r2_covid = r2_score(y_covid_test, y_covid_pred)\n",
    "    mape_covid = np.mean(np.abs((y_covid_test - y_covid_pred) / np.maximum(y_covid_test, 1))) * 100\n",
    "    \n",
    "    print(\"\\nüìä R√âSULTATS BACKTEST COVID:\")\n",
    "    print(f\"   MAE:  {mae_covid:.2f} hospitalisations/jour\")\n",
    "    print(f\"   RMSE: {rmse_covid:.2f}\")\n",
    "    print(f\"   R¬≤:   {r2_covid:.4f}\")\n",
    "    print(f\"   Moyenne hospitalisations: {y_covid_test.mean():.1f}/jour\")\n",
    "    print(f\"   Erreur relative: {(mae_covid/y_covid_test.mean())*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_COVID_DATA:\n",
    "    # Visualisation backtest COVID\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # S√©rie temporelle\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(dates_covid_test, y_covid_test.values, 'b-', label='R√©el', linewidth=1)\n",
    "    ax1.plot(dates_covid_test, y_covid_pred, 'r-', label='Pr√©dit', alpha=0.7)\n",
    "    ax1.set_title('Backtest COVID Paris - Hospitalisations')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Hospitalisations/jour')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Scatter\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(y_covid_test, y_covid_pred, alpha=0.5, s=20)\n",
    "    ax2.plot([0, y_covid_test.max()], [0, y_covid_test.max()], 'r--')\n",
    "    ax2.set_xlabel('R√©el')\n",
    "    ax2.set_ylabel('Pr√©dit')\n",
    "    ax2.set_title(f'Scatter (R¬≤ = {r2_covid:.3f})')\n",
    "    \n",
    "    # Erreurs par p√©riode\n",
    "    ax3 = axes[1, 0]\n",
    "    errors_covid = np.abs(y_covid_test.values - y_covid_pred)\n",
    "    ax3.hist(errors_covid, bins=40, edgecolor='black', alpha=0.7, color='coral')\n",
    "    ax3.axvline(mae_covid, color='r', linestyle='--', label=f'MAE: {mae_covid:.1f}')\n",
    "    ax3.set_title('Distribution des Erreurs')\n",
    "    ax3.set_xlabel('Erreur absolue')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Erreur en fonction du niveau\n",
    "    ax4 = axes[1, 1]\n",
    "    df_covid_results = pd.DataFrame({\n",
    "        'reel': y_covid_test.values,\n",
    "        'predit': y_covid_pred,\n",
    "        'erreur_pct': np.abs((y_covid_test.values - y_covid_pred) / np.maximum(y_covid_test.values, 1)) * 100\n",
    "    })\n",
    "    df_covid_results['niveau'] = pd.cut(df_covid_results['reel'], bins=[0, 20, 50, 100, 500], labels=['Faible', 'Moyen', '√âlev√©', 'Crise'])\n",
    "    error_by_level = df_covid_results.groupby('niveau')['erreur_pct'].mean()\n",
    "    colors = ['green', 'orange', 'red', 'darkred']\n",
    "    ax4.bar(error_by_level.index.astype(str), error_by_level.values, color=colors)\n",
    "    ax4.set_title('Erreur (%) par Niveau d\\'Activit√©')\n",
    "    ax4.set_ylabel('Erreur moyenne (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/viz_backtest_covid.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. R√©sum√© et Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìä R√âSUM√â FINAL - √âVALUATION DES MOD√àLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ PERFORMANCES SUR DONN√âES SYNTH√âTIQUES:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"   Random Forest:\")\n",
    "print(f\"      - MAE: {mae_rf:.2f} admissions/jour\")\n",
    "print(f\"      - R¬≤:  {r2_rf:.4f}\")\n",
    "print(f\"      - MAPE: {mape_rf:.2f}%\")\n",
    "if arima_fit:\n",
    "    print(f\"   ARIMA:\")\n",
    "    print(f\"      - MAE: {mae_arima:.2f}\")\n",
    "    print(f\"      - R¬≤:  {r2_arima:.4f}\")\n",
    "\n",
    "if HAS_COVID_DATA:\n",
    "    print(\"\\nü¶† PERFORMANCES SUR DONN√âES COVID R√âELLES:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"   Random Forest:\")\n",
    "    print(f\"      - MAE: {mae_covid:.2f} hospitalisations/jour\")\n",
    "    print(f\"      - R¬≤:  {r2_covid:.4f}\")\n",
    "    print(f\"      - Erreur relative: {(mae_covid/y_covid_test.mean())*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüìà FEATURES LES PLUS IMPORTANTES:\")\n",
    "print(\"-\"*50)\n",
    "for idx, row in importance.head(5).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.1%}\")\n",
    "\n",
    "print(\"\\nüí° CONCLUSIONS:\")\n",
    "print(\"-\"*50)\n",
    "print(\"   ‚Ä¢ Random Forest surpasse ARIMA sur ce type de donn√©es\")\n",
    "print(\"   ‚Ä¢ Les features de lag (J-7, J-1) sont les plus pr√©dictives\")\n",
    "print(\"   ‚Ä¢ Le mod√®le capture bien la saisonnalit√© hebdomadaire\")\n",
    "if HAS_COVID_DATA:\n",
    "    print(f\"   ‚Ä¢ Sur donn√©es r√©elles, erreur de ~{(mae_covid/y_covid_test.mean())*100:.0f}% en moyenne\")\n",
    "print(\"   ‚Ä¢ Fiable √† court terme (J+1 √† J+7), moins √† long terme\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les r√©sultats\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    'date_evaluation': datetime.now().isoformat(),\n",
    "    'donnees_synthetiques': {\n",
    "        'nb_jours_train': len(X_train),\n",
    "        'nb_jours_test': len(X_test),\n",
    "        'random_forest': {\n",
    "            'mae': round(mae_rf, 2),\n",
    "            'rmse': round(rmse_rf, 2),\n",
    "            'mape': round(mape_rf, 2),\n",
    "            'r2': round(r2_rf, 4)\n",
    "        },\n",
    "        'cross_validation': {\n",
    "            'mae_mean': round(np.mean(cv_scores_mae), 2),\n",
    "            'mae_std': round(np.std(cv_scores_mae), 2),\n",
    "            'r2_mean': round(np.mean(cv_scores_r2), 4),\n",
    "            'r2_std': round(np.std(cv_scores_r2), 4)\n",
    "        }\n",
    "    },\n",
    "    'features_importance': importance.head(10).to_dict('records')\n",
    "}\n",
    "\n",
    "if arima_fit:\n",
    "    results['donnees_synthetiques']['arima'] = {\n",
    "        'mae': round(mae_arima, 2),\n",
    "        'rmse': round(rmse_arima, 2),\n",
    "        'mape': round(mape_arima, 2),\n",
    "        'r2': round(r2_arima, 4)\n",
    "    }\n",
    "\n",
    "if HAS_COVID_DATA:\n",
    "    results['backtest_covid'] = {\n",
    "        'nb_jours_test': len(X_covid_test),\n",
    "        'mae': round(mae_covid, 2),\n",
    "        'rmse': round(rmse_covid, 2),\n",
    "        'r2': round(r2_covid, 4),\n",
    "        'erreur_relative_pct': round((mae_covid/y_covid_test.mean())*100, 1)\n",
    "    }\n",
    "\n",
    "with open('../data/model_evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ R√©sultats sauvegard√©s dans data/model_evaluation_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
