{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Comparaison des ModÃ¨les de PrÃ©diction\n",
    "## HÃ´pital PitiÃ©-SalpÃªtriÃ¨re\n",
    "\n",
    "Ce notebook compare les performances de diffÃ©rents modÃ¨les de prÃ©diction d'admissions hospitaliÃ¨res.\n",
    "\n",
    "### ModÃ¨les testÃ©s :\n",
    "1. **ARIMA** - ModÃ¨le statistique classique\n",
    "2. **Prophet** - ModÃ¨le Facebook pour sÃ©ries temporelles\n",
    "3. **Random Forest** - Ensemble d'arbres de dÃ©cision\n",
    "4. **Gradient Boosting** - Arbres sÃ©quentiels\n",
    "5. **Ensemble** - Combinaison pondÃ©rÃ©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"ğŸ“¦ BibliothÃ¨ques chargÃ©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnÃ©es d'Ã©tablissement\n",
    "df = pd.read_csv('../data/etablissement.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"ğŸ“… PÃ©riode : {df['date'].min().date()} â†’ {df['date'].max().date()}\")\n",
    "print(f\"ğŸ“Š Nombre de jours : {len(df)}\")\n",
    "print(f\"ğŸ¥ Admissions moyennes : {df['nb_admissions'].mean():.0f}/jour\")\n",
    "print(f\"   Min : {df['nb_admissions'].min():.0f} | Max : {df['nb_admissions'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des donnÃ©es\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(df['date'], df['nb_admissions'], alpha=0.7, linewidth=0.8)\n",
    "ax.axhline(df['nb_admissions'].mean(), color='red', linestyle='--', label=f\"Moyenne ({df['nb_admissions'].mean():.0f})\")\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Admissions quotidiennes')\n",
    "ax.set_title('Admissions HospitaliÃ¨res Quotidiennes (2020-2025)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explication des MÃ©triques d'Ã‰valuation\n",
    "\n",
    "### 2.1 MAE (Mean Absolute Error) - Erreur Absolue Moyenne\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "\n",
    "**InterprÃ©tation** : Erreur moyenne en valeur absolue. Une MAE de 6 signifie que le modÃ¨le se trompe de Â±6 admissions en moyenne.\n",
    "\n",
    "### 2.2 RMSE (Root Mean Square Error)\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "**InterprÃ©tation** : PÃ©nalise davantage les grosses erreurs. Si RMSE >> MAE, il y a des erreurs importantes ponctuelles.\n",
    "\n",
    "### 2.3 MAPE (Mean Absolute Percentage Error)\n",
    "\n",
    "$$MAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right|$$\n",
    "\n",
    "**InterprÃ©tation** : Erreur en pourcentage. Une MAPE de 1.25% signifie que le modÃ¨le se trompe de 1.25% en moyenne.\n",
    "\n",
    "### 2.4 RÂ² (Coefficient de DÃ©termination)\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}$$\n",
    "\n",
    "**InterprÃ©tation** : Proportion de variance expliquÃ©e. RÂ² = 0.98 signifie que le modÃ¨le explique 98% de la variabilitÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustration des mÃ©triques\n",
    "np.random.seed(42)\n",
    "y_true = np.array([100, 150, 200, 180, 220])\n",
    "y_pred = np.array([95, 160, 190, 185, 210])\n",
    "\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "r2 = 1 - np.sum((y_true - y_pred)**2) / np.sum((y_true - np.mean(y_true))**2)\n",
    "\n",
    "print(\"Exemple simple avec 5 observations :\")\n",
    "print(f\"Valeurs rÃ©elles : {y_true}\")\n",
    "print(f\"PrÃ©dictions     : {y_pred}\")\n",
    "print(f\"Erreurs         : {y_true - y_pred}\")\n",
    "print()\n",
    "print(f\"MAE  = {mae:.2f} (erreur moyenne de Â±{mae:.0f})\")\n",
    "print(f\"RMSE = {rmse:.2f}\")\n",
    "print(f\"MAPE = {mape:.2f}% (erreur de {mape:.1f}% en moyenne)\")\n",
    "print(f\"RÂ²   = {r2:.4f} (explique {r2*100:.1f}% de la variance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RÃ©sultats de la Comparaison des ModÃ¨les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©sultats des tests (issus de nos expÃ©rimentations)\n",
    "resultats = {\n",
    "    'ModÃ¨le': ['Gradient Boosting', 'Random Forest', 'Ensemble', 'Prophet', 'ARIMA'],\n",
    "    'MAE': [6.52, 7.84, 7.37, 54.53, 61.68],\n",
    "    'RMSE': [9.89, 11.12, 10.41, 63.68, 76.91],\n",
    "    'MAPE (%)': [1.25, 1.51, 1.45, 11.34, 13.44],\n",
    "    'RÂ²': [0.9842, 0.9800, 0.9825, 0.3435, 0.0424]\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(resultats)\n",
    "df_results = df_results.set_index('ModÃ¨le')\n",
    "\n",
    "# Affichage avec style\n",
    "def highlight_best(s):\n",
    "    if s.name in ['MAE', 'RMSE', 'MAPE (%)']:\n",
    "        is_best = s == s.min()\n",
    "    else:  # RÂ²\n",
    "        is_best = s == s.max()\n",
    "    return ['background-color: #90EE90' if v else '' for v in is_best]\n",
    "\n",
    "df_results.style.apply(highlight_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = ['#2ecc71', '#3498db', '#9b59b6', '#f39c12', '#e74c3c']\n",
    "modeles = df_results.index.tolist()\n",
    "\n",
    "# MAE\n",
    "axes[0, 0].barh(modeles, df_results['MAE'], color=colors)\n",
    "axes[0, 0].set_xlabel('MAE (admissions)')\n",
    "axes[0, 0].set_title('MAE - Erreur Absolue Moyenne\\n(plus bas = meilleur)')\n",
    "for i, v in enumerate(df_results['MAE']):\n",
    "    axes[0, 0].text(v + 1, i, f'{v:.2f}', va='center')\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].barh(modeles, df_results['RMSE'], color=colors)\n",
    "axes[0, 1].set_xlabel('RMSE')\n",
    "axes[0, 1].set_title('RMSE - Racine Erreur Quadratique Moyenne\\n(plus bas = meilleur)')\n",
    "for i, v in enumerate(df_results['RMSE']):\n",
    "    axes[0, 1].text(v + 1, i, f'{v:.2f}', va='center')\n",
    "\n",
    "# MAPE\n",
    "axes[1, 0].barh(modeles, df_results['MAPE (%)'], color=colors)\n",
    "axes[1, 0].set_xlabel('MAPE (%)')\n",
    "axes[1, 0].set_title('MAPE - Erreur en Pourcentage\\n(plus bas = meilleur)')\n",
    "for i, v in enumerate(df_results['MAPE (%)']):\n",
    "    axes[1, 0].text(v + 0.3, i, f'{v:.2f}%', va='center')\n",
    "\n",
    "# RÂ²\n",
    "axes[1, 1].barh(modeles, df_results['RÂ²'], color=colors)\n",
    "axes[1, 1].set_xlabel('RÂ²')\n",
    "axes[1, 1].set_title('RÂ² - Coefficient de DÃ©termination\\n(plus haut = meilleur)')\n",
    "axes[1, 1].set_xlim(0, 1.1)\n",
    "for i, v in enumerate(df_results['RÂ²']):\n",
    "    axes[1, 1].text(v + 0.02, i, f'{v:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/comparaison_modeles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“Š Graphique sauvegardÃ© dans docs/comparaison_modeles.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse des RÃ©sultats\n",
    "\n",
    "### ğŸ† Classement des modÃ¨les\n",
    "\n",
    "1. **Gradient Boosting** - Meilleur sur toutes les mÃ©triques\n",
    "2. **Ensemble** - TrÃ¨s proche, combine les forces des modÃ¨les\n",
    "3. **Random Forest** - Excellent Ã©galement\n",
    "4. **Prophet** - Performance moyenne\n",
    "5. **ARIMA** - Le moins performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart pour visualiser les forces de chaque modÃ¨le\n",
    "from math import pi\n",
    "\n",
    "# Normaliser les mÃ©triques (0-1, inversÃ© pour MAE/RMSE/MAPE)\n",
    "df_norm = df_results.copy()\n",
    "df_norm['MAE'] = 1 - (df_results['MAE'] - df_results['MAE'].min()) / (df_results['MAE'].max() - df_results['MAE'].min())\n",
    "df_norm['RMSE'] = 1 - (df_results['RMSE'] - df_results['RMSE'].min()) / (df_results['RMSE'].max() - df_results['RMSE'].min())\n",
    "df_norm['MAPE (%)'] = 1 - (df_results['MAPE (%)'] - df_results['MAPE (%)'].min()) / (df_results['MAPE (%)'].max() - df_results['MAPE (%)'].min())\n",
    "# RÂ² est dÃ©jÃ  dans le bon sens\n",
    "\n",
    "# Radar chart\n",
    "categories = list(df_norm.columns)\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "\n",
    "for i, model in enumerate(df_norm.index[:3]):  # Top 3 modÃ¨les\n",
    "    values = df_norm.loc[model].values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i])\n",
    "    ax.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title('Comparaison des 3 Meilleurs ModÃ¨les\\n(plus grand = meilleur)', size=14, y=1.1)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering - Ce qui fait la diffÃ©rence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©monstration de l'importance du feature engineering\n",
    "print(\"ğŸ“Š Nombre de features par approche :\")\n",
    "print()\n",
    "print(\"ARIMA / Prophet (modÃ¨les statistiques) :\")\n",
    "print(\"   â†’ Utilisent uniquement la sÃ©rie temporelle brute\")\n",
    "print(\"   â†’ Pas de features supplÃ©mentaires\")\n",
    "print()\n",
    "print(\"Random Forest / Gradient Boosting (version basique) :\")\n",
    "print(\"   â†’ ~10 features : jour semaine, mois, lag_1, lag_7, ma_7...\")\n",
    "print(\"   â†’ MAE â‰ˆ 31\")\n",
    "print()\n",
    "print(\"Random Forest / Gradient Boosting (version optimisÃ©e) :\")\n",
    "print(\"   â†’ 135 features !\")\n",
    "print(\"   â†’ MAE â‰ˆ 6.5\")\n",
    "print()\n",
    "print(\"â¡ï¸ AmÃ©lioration de -79% grÃ¢ce au feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des catÃ©gories de features\n",
    "features_categories = {\n",
    "    'Temporelles de base': [\n",
    "        'day_of_week', 'day_of_month', 'month', 'quarter', 'week_of_year', 'year'\n",
    "    ],\n",
    "    'Cycliques (sin/cos)': [\n",
    "        'sin_day_week', 'cos_day_week', 'sin_month', 'cos_month', 'sin_day_month', 'cos_day_month'\n",
    "    ],\n",
    "    'Binaires': [\n",
    "        'is_weekend', 'is_monday', 'is_friday', 'is_winter', 'is_spring', 'is_summer', 'is_autumn',\n",
    "        'is_month_start', 'is_month_end'\n",
    "    ],\n",
    "    'Lags (historique)': [\n",
    "        'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'lag_14', 'lag_21', 'lag_28', 'lag_30'\n",
    "    ],\n",
    "    'Moyennes mobiles': [\n",
    "        'ma_3', 'ma_5', 'ma_7', 'ma_14', 'ma_21', 'ma_30'\n",
    "    ],\n",
    "    'Ã‰carts-types': [\n",
    "        'std_3', 'std_5', 'std_7', 'std_14', 'std_21', 'std_30'\n",
    "    ],\n",
    "    'Min/Max glissants': [\n",
    "        'min_3', 'max_3', 'min_7', 'max_7', 'min_14', 'max_14', 'min_30', 'max_30', 'etc.'\n",
    "    ],\n",
    "    'EMA (exponentielle)': [\n",
    "        'ema_7', 'ema_14', 'ema_30'\n",
    "    ],\n",
    "    'Tendances': [\n",
    "        'trend_1d', 'trend_7d', 'trend_14d', 'trend_30d', 'pct_change_1d', 'pct_change_7d'\n",
    "    ],\n",
    "    'MÃªme jour semaine prÃ©cÃ©dente': [\n",
    "        'same_day_last_week', 'same_day_2weeks_ago', 'same_day_4weeks_ago'\n",
    "    ],\n",
    "    'Ratios': [\n",
    "        'ratio_to_ma7', 'ratio_to_ma30'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ CatÃ©gories de Features (135 au total) :\")\n",
    "print(\"=\"*50)\n",
    "for cat, feats in features_categories.items():\n",
    "    print(f\"\\n{cat} ({len(feats)} features) :\")\n",
    "    print(f\"   {', '.join(feats[:5])}{'...' if len(feats) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "### RÃ©sumÃ© des rÃ©sultats\n",
    "\n",
    "| Aspect | RÃ©sultat |\n",
    "|--------|----------|\n",
    "| **Meilleur modÃ¨le** | Gradient Boosting |\n",
    "| **MAE** | 6.52 admissions (erreur de Â±6 patients/jour) |\n",
    "| **RÂ²** | 0.98 (explique 98% de la variance) |\n",
    "| **MAPE** | 1.25% (erreur relative trÃ¨s faible) |\n",
    "\n",
    "### Pourquoi les modÃ¨les ML surpassent ARIMA/Prophet ?\n",
    "\n",
    "1. **Feature engineering** : 135 variables capturant diffÃ©rents aspects temporels\n",
    "2. **Non-linÃ©aritÃ©** : Les modÃ¨les Ã  base d'arbres capturent des relations complexes\n",
    "3. **Interactions** : GB/RF peuvent modÃ©liser les interactions entre variables\n",
    "\n",
    "### Recommandations\n",
    "\n",
    "- Utiliser **Gradient Boosting** en production\n",
    "- RÃ©entraÃ®ner rÃ©guliÃ¨rement (mensuel) avec les nouvelles donnÃ©es\n",
    "- Surveiller les mÃ©triques pour dÃ©tecter une dÃ©gradation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©sumÃ© final\n",
    "print(\"=\"*60)\n",
    "print(\"                    RÃ‰SUMÃ‰ FINAL\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"ğŸ† Meilleur modÃ¨le : Gradient Boosting\")\n",
    "print()\n",
    "print(\"ğŸ“Š Performances :\")\n",
    "print(f\"   â€¢ MAE  = 6.52 (erreur de Â±6 admissions/jour)\")\n",
    "print(f\"   â€¢ RÂ²   = 0.98 (98% de variance expliquÃ©e)\")\n",
    "print(f\"   â€¢ MAPE = 1.25% (erreur relative)\")\n",
    "print()\n",
    "print(\"ğŸ“ˆ AmÃ©lioration vs ARIMA (baseline) :\")\n",
    "print(f\"   â€¢ MAE  : 61.68 â†’ 6.52 (-89%)\")\n",
    "print(f\"   â€¢ RÂ²   : 0.04 â†’ 0.98 (+2200%)\")\n",
    "print()\n",
    "print(\"ğŸ”‘ Facteur clÃ© : Feature Engineering (135 variables)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
