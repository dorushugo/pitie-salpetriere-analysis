{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Mod√®le d'IA - Pr√©diction d'Activit√© Hospitali√®re\n",
    "\n",
    "Ce notebook entra√Æne et √©value les mod√®les de pr√©diction pour l'activit√© hospitali√®re de Piti√©-Salp√™tri√®re.\n",
    "\n",
    "**Mod√®les:**\n",
    "- Random Forest (Machine Learning)\n",
    "- ARIMA (Time Series)\n",
    "- Ensemble (Combinaison pond√©r√©e)\n",
    "\n",
    "**Donn√©es:**\n",
    "- Admissions synth√©tiques calibr√©es sur donn√©es r√©elles SAE\n",
    "- Donn√©es COVID r√©elles (Sant√© Publique France)\n",
    "- Indicateurs Hospi-Diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Time Series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Configuration\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MODEL_DIR = DATA_DIR / 'models'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "(DATA_DIR / 'graphs').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques charg√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les admissions\n",
    "df_admissions = pd.read_csv(DATA_DIR / 'admissions.csv')\n",
    "df_admissions['date'] = pd.to_datetime(df_admissions['date_admission'])\n",
    "\n",
    "print(f\"üìä Admissions charg√©es: {len(df_admissions):,} lignes\")\n",
    "print(f\"üìÖ P√©riode: {df_admissions['date'].min().date()} ‚Üí {df_admissions['date'].max().date()}\")\n",
    "print(f\"\\nüìã Colonnes: {list(df_admissions.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agr√©gation journali√®re simple\n",
    "df_daily = df_admissions.groupby(df_admissions['date'].dt.date).size().reset_index()\n",
    "df_daily.columns = ['date', 'admissions']\n",
    "df_daily['date'] = pd.to_datetime(df_daily['date'])\n",
    "df_daily = df_daily.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"üìà Donn√©es journali√®res: {len(df_daily)} jours\")\n",
    "print(f\"   Admissions/jour: {df_daily['admissions'].mean():.0f} (min: {df_daily['admissions'].min()}, max: {df_daily['admissions'].max()})\")\n",
    "\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# S√©rie temporelle\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df_daily['date'], df_daily['admissions'], alpha=0.7, linewidth=0.8)\n",
    "ax1.set_title('Admissions journali√®res', fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Admissions')\n",
    "\n",
    "# Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df_daily['admissions'], bins=30, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(df_daily['admissions'].mean(), color='red', linestyle='--', label=f\"Moyenne: {df_daily['admissions'].mean():.0f}\")\n",
    "ax2.set_title('Distribution des admissions', fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "# Par jour de semaine\n",
    "ax3 = axes[1, 0]\n",
    "df_daily['dow'] = df_daily['date'].dt.dayofweek\n",
    "dow_names = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']\n",
    "dow_stats = df_daily.groupby('dow')['admissions'].mean()\n",
    "ax3.bar(dow_names, dow_stats.values, color='#2ecc71', edgecolor='black')\n",
    "ax3.set_title('Moyenne par jour de semaine', fontweight='bold')\n",
    "ax3.set_ylabel('Admissions moyennes')\n",
    "\n",
    "# Par mois\n",
    "ax4 = axes[1, 1]\n",
    "df_daily['month'] = df_daily['date'].dt.month\n",
    "month_names = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Juin', 'Juil', 'Ao√ªt', 'Sep', 'Oct', 'Nov', 'D√©c']\n",
    "month_stats = df_daily.groupby('month')['admissions'].mean()\n",
    "colors = ['#e74c3c' if m in [1, 2, 12] else '#3498db' for m in month_stats.index]  # Hiver en rouge\n",
    "ax4.bar(month_names, month_stats.values, color=colors, edgecolor='black')\n",
    "ax4.set_title('Moyenne par mois (saisonnalit√© - rouge=hiver)', fontweight='bold')\n",
    "ax4.set_ylabel('Admissions moyennes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/graphs/exploration_admissions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Cr√©e les features pour le mod√®le ML.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features temporelles de base\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['year'] = df['date'].dt.year\n",
    "    \n",
    "    # Encodage cyclique\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Indicateurs binaires\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['is_monday'] = (df['day_of_week'] == 0).astype(int)\n",
    "    df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)\n",
    "    df['is_summer'] = df['month'].isin([7, 8]).astype(int)\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in [1, 7, 14]:\n",
    "        df[f'lag_{lag}'] = df['admissions'].shift(lag)\n",
    "    \n",
    "    # Rolling features\n",
    "    df['rolling_mean_7'] = df['admissions'].shift(1).rolling(window=7, min_periods=1).mean()\n",
    "    df['rolling_std_7'] = df['admissions'].shift(1).rolling(window=7, min_periods=1).std()\n",
    "    df['rolling_mean_14'] = df['admissions'].shift(1).rolling(window=14, min_periods=1).mean()\n",
    "    \n",
    "    # Tendance\n",
    "    df['trend'] = range(len(df))\n",
    "    \n",
    "    # Remplir les NaN pour les premiers jours\n",
    "    df = df.fillna(method='bfill').fillna(df['admissions'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_features = create_features(df_daily)\n",
    "print(f\"‚úÖ Features cr√©√©es: {len(df_features)} lignes, {len(df_features.columns)} colonnes\")\n",
    "\n",
    "# Liste des features\n",
    "feature_cols = [c for c in df_features.columns if c not in ['date', 'admissions', 'dow', 'month']]\n",
    "print(f\"\\nüìä Features ({len(feature_cols)}): {feature_cols[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entra√Ænement Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration donn√©es\n",
    "X = df_features[feature_cols].values\n",
    "y = df_features['admissions'].values\n",
    "\n",
    "# Split temporel (80% train, 20% test)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "dates_test = df_features['date'].iloc[split_idx:].values\n",
    "\n",
    "print(f\"üìä Train: {len(X_train)} jours\")\n",
    "print(f\"üìä Test: {len(X_test)} jours\")\n",
    "\n",
    "# Entra√Ænement\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"\\n‚úÖ Mod√®le Random Forest entra√Æn√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# M√©triques\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mape_rf = np.mean(np.abs((y_test - y_pred_rf) / y_test)) * 100\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"üìä M√âTRIQUES RANDOM FOREST:\")\n",
    "print(f\"   MAE:  {mae_rf:.2f} admissions\")\n",
    "print(f\"   RMSE: {rmse_rf:.2f} admissions\")\n",
    "print(f\"   MAPE: {mape_rf:.1f}%\")\n",
    "print(f\"   R¬≤:   {r2_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = importance.head(15)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "ax.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Top 15 Features - Random Forest', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/graphs/feature_importance_rf.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Top 5 features:\")\n",
    "for i, (_, row) in enumerate(importance.head(5).iterrows()):\n",
    "    print(f\"   {i+1}. {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entra√Ænement ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de stationnarit√©\n",
    "adf_result = adfuller(df_daily['admissions'])\n",
    "print(f\"üìä Test ADF (stationnarit√©):\")\n",
    "print(f\"   Statistique: {adf_result[0]:.4f}\")\n",
    "print(f\"   p-value: {adf_result[1]:.4f}\")\n",
    "print(f\"   Stationnaire: {'Oui ‚úì' if adf_result[1] < 0.05 else 'Non ‚úó'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement ARIMA\n",
    "train_data = df_daily['admissions'].iloc[:split_idx]\n",
    "test_data = df_daily['admissions'].iloc[split_idx:]\n",
    "\n",
    "print(\"‚è≥ Entra√Ænement ARIMA(5,1,2)...\")\n",
    "arima_model = ARIMA(train_data, order=(5, 1, 2))\n",
    "arima_fitted = arima_model.fit()\n",
    "print(\"‚úÖ ARIMA entra√Æn√©\")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_arima = arima_fitted.forecast(steps=len(test_data))\n",
    "\n",
    "# M√©triques\n",
    "mae_arima = mean_absolute_error(test_data, y_pred_arima)\n",
    "rmse_arima = np.sqrt(mean_squared_error(test_data, y_pred_arima))\n",
    "mape_arima = np.mean(np.abs((test_data.values - y_pred_arima.values) / test_data.values)) * 100\n",
    "r2_arima = r2_score(test_data, y_pred_arima)\n",
    "\n",
    "print(\"\\nüìä M√âTRIQUES ARIMA:\")\n",
    "print(f\"   MAE:  {mae_arima:.2f} admissions\")\n",
    "print(f\"   RMSE: {rmse_arima:.2f} admissions\")\n",
    "print(f\"   MAPE: {mape_arima:.1f}%\")\n",
    "print(f\"   R¬≤:   {r2_arima:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison et Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Pr√©dictions vs R√©el\n",
    "ax1 = axes[0]\n",
    "ax1.plot(dates_test, y_test, 'b-', label='R√©el', alpha=0.7, linewidth=1)\n",
    "ax1.plot(dates_test, y_pred_rf, 'r--', label=f'Random Forest (MAE={mae_rf:.1f})', alpha=0.7, linewidth=1)\n",
    "ax1.plot(dates_test, y_pred_arima.values, 'g:', label=f'ARIMA (MAE={mae_arima:.1f})', alpha=0.7, linewidth=1)\n",
    "ax1.set_title('Pr√©dictions vs R√©el', fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Admissions')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Erreurs\n",
    "ax2 = axes[1]\n",
    "ax2.fill_between(dates_test, 0, y_test - y_pred_rf, alpha=0.3, color='red', label='Erreur RF')\n",
    "ax2.fill_between(dates_test, 0, y_test - y_pred_arima.values, alpha=0.3, color='green', label='Erreur ARIMA')\n",
    "ax2.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_title('Erreurs de pr√©diction', fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Erreur (R√©el - Pr√©dit)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/graphs/comparaison_modeles.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison = pd.DataFrame({\n",
    "    'M√©trique': ['MAE', 'RMSE', 'MAPE (%)', 'R¬≤'],\n",
    "    'Random Forest': [f\"{mae_rf:.2f}\", f\"{rmse_rf:.2f}\", f\"{mape_rf:.1f}\", f\"{r2_rf:.3f}\"],\n",
    "    'ARIMA': [f\"{mae_arima:.2f}\", f\"{rmse_arima:.2f}\", f\"{mape_arima:.1f}\", f\"{r2_arima:.3f}\"]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*50)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde et R√©sum√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le mod√®le\n",
    "joblib.dump(rf_model, MODEL_DIR / 'random_forest_model.pkl')\n",
    "print(f\"‚úÖ Mod√®le sauvegard√©: {MODEL_DIR / 'random_forest_model.pkl'}\")\n",
    "\n",
    "# Sauvegarder les m√©triques\n",
    "import json\n",
    "metrics = {\n",
    "    'random_forest': {'mae': mae_rf, 'rmse': rmse_rf, 'mape': mape_rf, 'r2': r2_rf},\n",
    "    'arima': {'mae': mae_arima, 'rmse': rmse_arima, 'mape': mape_arima, 'r2': r2_arima},\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test)\n",
    "}\n",
    "\n",
    "with open(MODEL_DIR / 'model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"‚úÖ M√©triques: {MODEL_DIR / 'model_metrics.json'}\")\n",
    "\n",
    "# R√©sum√©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä R√âSUM√â MOD√àLE IA\")\n",
    "print(\"=\"*60)\n",
    "best = 'Random Forest' if mae_rf < mae_arima else 'ARIMA'\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best}\")\n",
    "print(f\"   MAE: {min(mae_rf, mae_arima):.1f} admissions/jour\")\n",
    "print(f\"   Pr√©cision: {100 - min(mape_rf, mape_arima):.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
